# å®Ÿé¨“å®Ÿè¡Œã‚¬ã‚¤ãƒ‰

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

H100ãŒ8æšã‚ã‚‹ç’°å¢ƒã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ã§å…¨å®Ÿé¨“ãŒå®Œäº†ã—ã¾ã™ï¼š

```bash
./run_complete_experiments.sh
```

## ğŸ“‹ å®Ÿé¨“ã®æµã‚Œ

### 1. **äº‹å‰æº–å‚™** (è‡ªå‹•)
- GPUã®ç¢ºèª
- ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ

### 2. **ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰** (2-3æ™‚é–“)
```bash
# å€‹åˆ¥å®Ÿè¡Œã™ã‚‹å ´åˆ
python3 scripts/download_qwen2.5_models.py --base-path /raid/$USER/models
```
- Qwen2.5-7B (15GB)
- Qwen2.5-14B (28GB)
- Qwen2.5-32B (65GB)
- Qwen2.5-72B (145GB)

### 3. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™** (30åˆ†)
```bash
# å€‹åˆ¥å®Ÿè¡Œã™ã‚‹å ´åˆ
python3 setup_datasets.py --output-dir /raid/$USER/datasets
```
- MMLU: 2000ã‚µãƒ³ãƒ—ãƒ«
- HumanEval: 164ã‚µãƒ³ãƒ—ãƒ«
- MT-Benché¢¨: 100ã‚µãƒ³ãƒ—ãƒ«
- Simple Q&A: 500ã‚µãƒ³ãƒ—ãƒ«

### 4. **è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ** (4-5æ™‚é–“)
```bash
# å€‹åˆ¥å®Ÿè¡Œã™ã‚‹å ´åˆ
python3 src/training/generate_training_data.py \
    --dataset /raid/$USER/datasets/mmlu_test.json \
    --model-paths /raid/$USER/models/model_paths.json \
    --output-dir /raid/$USER/training_data
```
- å„ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–å®Ÿè¡Œ
- BLEUã‚¹ã‚³ã‚¢è¨ˆç®—
- ç‰¹å¾´é‡æŠ½å‡º

### 5. **å“è³ªäºˆæ¸¬å™¨ã®å­¦ç¿’** (1æ™‚é–“)
- 32æ¬¡å…ƒMLPã®å­¦ç¿’
- 50ã‚¨ãƒãƒƒã‚¯
- æ¤œè¨¼ç²¾åº¦ã®ç¢ºèª

### 6. **è©•ä¾¡å®Ÿé¨“** (2æ™‚é–“)
- ç†è«–çš„æ¤œè¨¼
- å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
- çµ±è¨ˆçš„æ¤œå®š

## ğŸ“Š å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«

å®Ÿé¨“å®Œäº†å¾Œã€ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã™ï¼š

```
/raid/$USER/adaptive-speculative-decoding/results/run_YYYYMMDD_HHMMSS/
â”œâ”€â”€ experiment_report.md      # å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆ
â”œâ”€â”€ evaluation_results.json   # è©•ä¾¡çµæœ
â”œâ”€â”€ theoretical_results_simple.png  # ç†è«–çš„çµæœã®å›³
â”œâ”€â”€ paper_results.png        # è«–æ–‡ç”¨ã®å›³
â””â”€â”€ paper_results.pdf        # è«–æ–‡ç”¨ã®å›³ï¼ˆPDFï¼‰
```

## ğŸ” ãƒ­ã‚°ã®ç¢ºèª

ã™ã¹ã¦ã®ãƒ­ã‚°ã¯ä»¥ä¸‹ã«ä¿å­˜ã•ã‚Œã¾ã™ï¼š
```
/raid/$USER/adaptive-speculative-decoding/logs/
â”œâ”€â”€ experiment_YYYYMMDD_HHMMSS.log      # ãƒ¡ã‚¤ãƒ³ãƒ­ã‚°
â”œâ”€â”€ model_download_YYYYMMDD_HHMMSS.log  # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ­ã‚°
â”œâ”€â”€ dataset_setup_YYYYMMDD_HHMMSS.log   # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ãƒ­ã‚°
â”œâ”€â”€ training_data_gen_YYYYMMDD_HHMMSS.log  # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ­ã‚°
â”œâ”€â”€ predictor_training_YYYYMMDD_HHMMSS.log # äºˆæ¸¬å™¨å­¦ç¿’ãƒ­ã‚°
â””â”€â”€ real_experiments_YYYYMMDD_HHMMSS.log   # è©•ä¾¡å®Ÿé¨“ãƒ­ã‚°
```

## âš¡ GPUä½¿ç”¨çŠ¶æ³

å®Ÿé¨“ä¸­ã®GPUå‰²ã‚Šå½“ã¦ï¼š
- GPU 0: Qwen2.5-7B
- GPU 1: Qwen2.5-14B
- GPU 2-3: Qwen2.5-32B
- GPU 4-7: Qwen2.5-72B

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¤±æ•—ã™ã‚‹å ´åˆ
```bash
# HuggingFaceãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®š
export HF_TOKEN="your_token_here"

# å†åº¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
python3 scripts/download_qwen2.5_models.py --token $HF_TOKEN
```

### ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆ
```bash
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã—ã¦å†å®Ÿè¡Œ
python3 src/training/generate_training_data.py \
    --batch-size 4  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯8
```

### å®Ÿé¨“ã‚’é€”ä¸­ã‹ã‚‰å†é–‹ã™ã‚‹å ´åˆ
```bash
# æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦å®Ÿé¨“ã®ã¿å®Ÿè¡Œ
python3 run_real_experiments.py --skip-training
```

## ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹çµæœ

æ­£å¸¸ã«å®Œäº†ã—ãŸå ´åˆï¼š
- **å¹³å‡é«˜é€ŸåŒ–**: 3-4å€
- **ã‚³ã‚¹ãƒˆå‰Šæ¸›**: 60-70%
- **å“è³ªä¿æŒ**: 95%ä»¥ä¸Š
- **çµ±è¨ˆçš„æœ‰æ„æ€§**: p < 0.001

## ğŸ’¡ Tips

1. **ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡**: æœ€ä½300GBå¿…è¦
2. **å®Ÿè¡Œæ™‚é–“**: å…¨ä½“ã§ç´„10æ™‚é–“
3. **ä¸¦åˆ—å®Ÿè¡Œ**: ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯ä¸¦åˆ—åŒ–ã•ã‚Œã¦ã„ã¾ã™
4. **ä¸­æ–­å¯¾å¿œ**: å„ãƒ•ã‚§ãƒ¼ã‚ºã¯ç‹¬ç«‹ã—ã¦ã„ã‚‹ãŸã‚ã€é€”ä¸­ã‹ã‚‰å†é–‹å¯èƒ½

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

å®Ÿé¨“å®Œäº†å¾Œï¼š
1. `experiment_report.md`ã§çµæœã‚’ç¢ºèª
2. `PAPER.md`ã®æ•°å€¤ã‚’å®Ÿæ¸¬å€¤ã§æ›´æ–°
3. å›³è¡¨ã‚’è«–æ–‡ã«çµ„ã¿è¾¼ã¿
4. è¿½åŠ å®Ÿé¨“ãŒå¿…è¦ãªå ´åˆã¯å€‹åˆ¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ