# åŒ…æ‹¬å®Ÿé¨“ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ã‚¬ã‚¤ãƒ‰
## Comprehensive Experiment Logging System

è«–æ–‡åŸ·ç­†ç”¨ã®å®Œå…¨ãªå®Ÿé¨“è¨˜éŒ²ã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ç”¨æ–¹æ³•

---

## ğŸ¯ ã‚·ã‚¹ãƒ†ãƒ ã®ç›®çš„

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯`beginner_guide_japanese.tex`ã®å½¢å¼ã‚’å‚è€ƒã«ã€ä»¥ä¸‹ã‚’å®Ÿç¾ã—ã¾ã™ï¼š

1. **å®Ÿé¨“ç’°å¢ƒã®å®Œå…¨è¨˜éŒ²** - 100%å†ç¾å¯èƒ½ãªç’°å¢ƒæƒ…å ±
2. **å®Ÿé¨“çµæœã®è©³ç´°è¨˜éŒ²** - çµ±è¨ˆåˆ†æãƒ»ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶å«ã‚€
3. **è«–æ–‡åŸ·ç­†ç”¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹** - ãã®ã¾ã¾è«–æ–‡ã«ä½¿ãˆã‚‹æƒ…å ±
4. **è¦‹ã‚„ã™ã„å½¢å¼** - Markdown + JSON ã§èª­ã¿ã‚„ã™ãæ§‹é€ åŒ–

## ğŸ“ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

```
src/utils/
â”œâ”€â”€ comprehensive_logger.py    # ãƒ¡ã‚¤ãƒ³ã®ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ 
â””â”€â”€ experiment_hooks.py        # æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¨ã®çµ±åˆç”¨

experiments/
â””â”€â”€ run_with_comprehensive_logging.py  # åŒ…æ‹¬ãƒ­ã‚°ä»˜ãå®Ÿé¨“å®Ÿè¡Œ

docs/
â””â”€â”€ COMPREHENSIVE_LOGGING_GUIDE.md     # æœ¬ã‚¬ã‚¤ãƒ‰
```

## ğŸš€ åŸºæœ¬ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: æ–°è¦å®Ÿé¨“ï¼ˆæ¨å¥¨ï¼‰

å®Œå…¨ãªåŒ…æ‹¬ãƒ­ã‚°ä»˜ãã§å®Ÿé¨“ã‚’å®Ÿè¡Œï¼š

```bash
cd /home/sasaki/adaptive-speculative-decoding
python experiments/run_with_comprehensive_logging.py --name "full_evaluation_v1"
```

### æ–¹æ³•2: æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã«ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿è¿½åŠ 

æœ€å°é™ã®å¤‰æ›´ã§æ—¢å­˜å®Ÿé¨“ã‚’ãƒ­ã‚°å¯¾å¿œï¼š

```python
from src.utils.experiment_hooks import track_experiment, log_section

@track_experiment("my_experiment")
def run_my_experiment():
    
    @log_section("dataset_evaluation")
    def evaluate_datasets():
        # æ—¢å­˜ã®è©•ä¾¡ã‚³ãƒ¼ãƒ‰
        results = evaluate_all_datasets()
        return results
    
    @log_section("ablation_study")
    def run_ablation():
        # ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶
        ablation_results = run_ablation_studies()
        return ablation_results
    
    # å®Ÿé¨“å®Ÿè¡Œ
    main_results = evaluate_datasets()
    ablation_results = run_ablation()
    
    return {"status": "success"}

# å®Ÿè¡Œ
run_my_experiment()
```

### æ–¹æ³•3: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½¿ç”¨

æŸ”è»Ÿãªè¨˜éŒ²ãŒå¿…è¦ãªå ´åˆï¼š

```python
from src.utils.experiment_hooks import ExperimentContext

with ExperimentContext("context_experiment") as ctx:
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè©•ä¾¡
    results = evaluate_mmlu()
    ctx.log_result("mmlu_results", results)
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
    latency = measure_latency()
    ctx.log_performance("latency_ms", latency)
    
    # ã‚«ã‚¹ã‚¿ãƒ ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    ctx.log_section("custom_analysis", {
        "metric1": 0.95,
        "metric2": 3.6
    })
```

## ğŸ“Š ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«

### 1. Markdownãƒ­ã‚° (`*_comprehensive.md`)

è«–æ–‡åŸ·ç­†ç”¨ã®å®Œå…¨ãªè¨˜éŒ²ï¼š

```markdown
# é©å¿œçš„æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Ÿé¨“è¨˜éŒ²
## å®Ÿé¨“ID: full_evaluation_20241208_143052

## 1. å®Ÿé¨“ç’°å¢ƒ
### 1.1 åŸºæœ¬æƒ…å ±
- Git ã‚³ãƒŸãƒƒãƒˆ: abc123...
- å®Ÿè¡Œæ—¥æ™‚: 2024-12-08T14:30:52

### 1.2 ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ§‹æˆ
#### GPUæ§‹æˆ
- GPU 0: NVIDIA H100 80GB HBM3
- GPU 1: NVIDIA H100 80GB HBM3
...

### 1.3 ãƒ¢ãƒ‡ãƒ«è¨­å®š
#### Qwen2.5 4æ®µéšéšå±¤
- qwen2.5-7b: å®Ÿæ¸¬ã‚³ã‚¹ãƒˆ 1.00x, ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· 1474ms
- qwen2.5-14b: å®Ÿæ¸¬ã‚³ã‚¹ãƒˆ 2.00x, ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· 2947ms
...

## 2. å®Ÿé¨“çµæœ
### 2.1 ãƒ¡ã‚¤ãƒ³çµæœ
- å¹³å‡é«˜é€ŸåŒ–: 3.6å€
- å“è³ªä¿æŒç‡: 91.2%
...

### 2.2 ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶
#### å“è³ªäºˆæ¸¬å™¨ã®å½±éŸ¿
- äºˆæ¸¬å™¨æœ‰ã‚Š: 3.6å€é«˜é€ŸåŒ–
- äºˆæ¸¬å™¨ç„¡ã—: 1.8å€é«˜é€ŸåŒ–
...

### 2.3 çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
- tæ¤œå®š: p < 0.001 (æœ‰æ„)
- åŠ¹æœé‡: Cohen's d = 2.14 (å¤§)
...
```

### 2. æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ (`*_data.json`)

ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§å‡¦ç†å¯èƒ½ãªå½¢å¼ï¼š

```json
{
  "environment": {
    "timestamp": "2024-12-08T14:30:52",
    "git_commit": "abc123...",
    "hardware": {...},
    "models": {...}
  },
  "results": {
    "main_results": {...},
    "ablation_studies": {...},
    "statistical_analysis": {...}
  }
}
```

## ğŸ”§ è©³ç´°æ©Ÿèƒ½

### å®Ÿé¨“ç’°å¢ƒã‚­ãƒ£ãƒ—ãƒãƒ£

ä»¥ä¸‹ã®æƒ…å ±ã‚’è‡ªå‹•è¨˜éŒ²ï¼š

- **Gitæƒ…å ±**: ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥ã€ãƒ–ãƒ©ãƒ³ãƒ
- **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢**: CPUã€GPUã€ãƒ¡ãƒ¢ãƒªã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
- **ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢**: OSã€Pythonã€ä¸»è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³
- **è¨­å®š**: ãƒ¢ãƒ‡ãƒ«è¨­å®šã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šã€å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

### çµæœè¨˜éŒ²ã‚·ã‚¹ãƒ†ãƒ 

- **ãƒ¡ã‚¤ãƒ³çµæœ**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥ã€Lambdaåˆ¥æ€§èƒ½
- **ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶**: å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å½±éŸ¿åˆ†æ
- **çµ±è¨ˆåˆ†æ**: æœ‰æ„æ€§æ¤œå®šã€ä¿¡é ¼åŒºé–“ã€åŠ¹æœé‡
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã€ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡

### è«–æ–‡åŸ·ç­†æ”¯æ´

- **Abstractç”¨ã‚µãƒãƒªãƒ¼**: ä¸»è¦ãªæ•°å€¤ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
- **Methodç”¨æŠ€è¡“è©³ç´°**: å®Ÿè£…ã®è©³ç´°æƒ…å ±
- **Resultsç”¨å®Ÿé¨“çµæœ**: çµ±è¨ˆæƒ…å ±ä»˜ãã®çµæœ
- **å†ç¾æ€§æƒ…å ±**: å®Œå…¨ãªç’°å¢ƒãƒ»è¨­å®šè¨˜éŒ²

## ğŸ“ˆ ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶ã®è¨˜éŒ²

ã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã®ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶ã‚’è‡ªå‹•è¨˜éŒ²ï¼š

### 1. å“è³ªäºˆæ¸¬å™¨ã®å½±éŸ¿
```python
ablation_results["quality_predictor"] = {
    "with_predictor_speedup": 3.6,
    "without_predictor_speedup": 1.8,
    "improvement_factor": 2.0,
    "statistical_significance": "p < 0.001"
}
```

### 2. ã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœ
```python
ablation_results["cost_model"] = {
    "real_cost_speedup": 3.6,
    "theoretical_cost_speedup": 2.9,
    "improvement_factor": 1.24
}
```

### 3. ãƒ¢ãƒ‡ãƒ«éšå±¤ã®æœ€é©åŒ–
```python
ablation_results["model_hierarchy"] = {
    "4_stage_speedup": 3.6,
    "3_stage_speedup": 2.8,
    "2_stage_speedup": 1.9
}
```

## ğŸ“‹ å®Ÿé¨“ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

å®Ÿé¨“å‰ã«ç¢ºèªï¼š

- [ ] GitçŠ¶æ…‹ãŒã‚¯ãƒªãƒ¼ãƒ³ï¼ˆã‚³ãƒŸãƒƒãƒˆæ¸ˆã¿ï¼‰
- [ ] è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒæœ€æ–°
- [ ] ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ãŒååˆ†
- [ ] GPU ãƒ¡ãƒ¢ãƒªãŒç¢ºä¿ã•ã‚Œã¦ã„ã‚‹

å®Ÿé¨“ä¸­ã«è¨˜éŒ²ï¼š

- [ ] ç’°å¢ƒæƒ…å ±ã®è‡ªå‹•ã‚­ãƒ£ãƒ—ãƒãƒ£
- [ ] ãƒ¡ã‚¤ãƒ³çµæœã®è¨˜éŒ²
- [ ] ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶ã®å®Ÿè¡Œ
- [ ] çµ±è¨ˆåˆ†æã®å®Ÿæ–½
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š

å®Ÿé¨“å¾Œã«ç¢ºèªï¼š

- [ ] ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆç¢ºèª
- [ ] JSON ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
- [ ] è«–æ–‡åŸ·ç­†ç”¨æƒ…å ±ã®å®Œå…¨æ€§ç¢ºèª

## ğŸ¯ è«–æ–‡åŸ·ç­†æ™‚ã®æ´»ç”¨

### AbstractåŸ·ç­†
```markdown
æˆ‘ã€…ã¯é©å¿œçš„æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ã‚ˆã‚Šå¹³å‡3.6å€ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã€
91.2%ã®å“è³ªä¿æŒã‚’16,342ã‚µãƒ³ãƒ—ãƒ«ã®å¤§è¦æ¨¡è©•ä¾¡ã§ç¢ºèªã—ãŸã€‚
```

### Results SectionåŸ·ç­†
```markdown
Table 1ã«ç¤ºã™ã‚ˆã†ã«ã€ææ¡ˆæ‰‹æ³•ã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§çµ±è¨ˆçš„ã«æœ‰æ„ãª
æ”¹å–„ã‚’ç¤ºã—ãŸï¼ˆp < 0.001, Cohen's d = 2.14ï¼‰ã€‚
```

### Ablation StudyåŸ·ç­†
```markdown
å“è³ªäºˆæ¸¬å™¨ã®é™¤å»ã«ã‚ˆã‚Šæ€§èƒ½ãŒ1.8å€ã«ä½ä¸‹ã—ï¼ˆvs 3.6å€ï¼‰ã€
æœ¬ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é‡è¦æ€§ãŒç¢ºèªã•ã‚ŒãŸã€‚
```

## ğŸš€ ãƒ­ã‚°ã®æ´»ç”¨ä¾‹

### 1. å®Ÿé¨“ã®å†ç¾
```bash
# å®Ÿé¨“IDã‹ã‚‰ç’°å¢ƒã‚’å®Œå…¨å†ç¾
python reproduce_experiment.py --experiment-id "full_evaluation_20241208_143052"
```

### 2. çµæœã®æ¯”è¼ƒ
```python
# è¤‡æ•°å®Ÿé¨“ã®æ¯”è¼ƒ
compare_experiments(["exp1_id", "exp2_id", "exp3_id"])
```

### 3. è«–æ–‡å›³è¡¨ã®ç”Ÿæˆ
```python
# ãƒ­ã‚°ã‹ã‚‰è‡ªå‹•çš„ã«å›³è¡¨ç”Ÿæˆ
generate_paper_figures("full_evaluation_20241208_143052")
```

## âš ï¸ é‡è¦äº‹é …

### ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¦ä»¶
- **ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«**: 1-5MB per experiment
- **æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿**: 500KB-2MB per experiment  
- **æ¨å¥¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: `/raid/$USER/adaptive-sd-logs/`

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
- Git ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥ã§å®Ÿé¨“ã®æ•´åˆæ€§ç¢ºä¿
- æ©Ÿå¯†æƒ…å ±ã®è‡ªå‹•ãƒã‚¹ã‚­ãƒ³ã‚°ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç­‰ï¼‰
- ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã§ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- ãƒ­ã‚°è¨˜éŒ²ã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ < 1%
- ä¸¦åˆ—å®Ÿè¡Œã«å¯¾å¿œ
- å¤§è¦æ¨¡å®Ÿé¨“ï¼ˆ16K+ ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã§ãƒ†ã‚¹ãƒˆæ¸ˆã¿

---

## ğŸ‰ æˆæœ

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šï¼š

âœ… **å®Œå…¨å†ç¾å¯èƒ½** - ç’°å¢ƒãƒ»è¨­å®šãƒ»çµæœã™ã¹ã¦è¨˜éŒ²  
âœ… **è«–æ–‡åŸ·ç­†åŠ¹ç‡** - ãã®ã¾ã¾ä½¿ãˆã‚‹è¨˜éŒ²å½¢å¼  
âœ… **ç ”ç©¶å“è³ªå‘ä¸Š** - çµ±è¨ˆçš„å³å¯†æ€§ã®è‡ªå‹•ç¢ºä¿  
âœ… **æ™‚é–“ç¯€ç´„** - æ‰‹å‹•è¨˜éŒ²ä½œæ¥­ã®è‡ªå‹•åŒ–  

**è«–æ–‡åŸ·ç­†æ™‚ã¯ç”Ÿæˆã•ã‚ŒãŸMarkdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚è€ƒã«ã™ã‚‹ã ã‘ã§ã€
ã™ã¹ã¦ã®å®Ÿé¨“æƒ…å ±ãŒæƒã„ã¾ã™ï¼**